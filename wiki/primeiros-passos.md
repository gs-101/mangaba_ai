# ğŸ“ Primeiros Passos

Tutorial prÃ¡tico passo-a-passo para comeÃ§ar a usar o Mangaba AI. Este guia irÃ¡ levÃ¡-lo desde a instalaÃ§Ã£o bÃ¡sica atÃ© a criaÃ§Ã£o de seus primeiros agentes inteligentes.

## ğŸ“‹ O que vocÃª vai aprender

- âœ… Configurar o ambiente de desenvolvimento
- âœ… Criar seu primeiro agente
- âœ… Implementar comunicaÃ§Ã£o entre agentes (A2A)
- âœ… Usar contexto inteligente (MCP)
- âœ… Criar um sistema multi-agente bÃ¡sico

---

## ğŸš€ Passo 1: ConfiguraÃ§Ã£o Inicial

### **1.1 Verificar PrÃ©-requisitos**

```bash
# Verificar Python (deve ser 3.8+)
python --version

# Verificar pip
pip --version

# Verificar git
git --version
```

### **1.2 Clonar e Configurar Projeto**

```bash
# Clonar repositÃ³rio
git clone https://github.com/Mangaba-ai/mangaba_ai.git
cd mangaba_ai

# Criar ambiente virtual
python -m venv .venv

# Ativar ambiente virtual
# Linux/Mac:
source .venv/bin/activate
# Windows:
.venv\Scripts\activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### **1.3 Configurar API Keys**

```bash
# Copiar arquivo de configuraÃ§Ã£o
cp .env.example .env

# Editar arquivo .env
nano .env  # ou seu editor preferido
```

Configure no `.env`:
```bash
# ObrigatÃ³rio: API key do Google Gemini
GEMINI_API_KEY=sua_chave_api_aqui

# Opcional: Para modelos adicionais
OPENAI_API_KEY=sua_chave_openai

# ConfiguraÃ§Ãµes bÃ¡sicas
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO
```

### **1.4 Validar InstalaÃ§Ã£o**

```bash
# Teste bÃ¡sico
python -c "from mangaba_ai import MangabaAI; print('âœ… Mangaba AI instalado com sucesso!')"

# Executar testes (opcional)
pytest tests/test_basic.py -v
```

---

## ğŸ¤– Passo 2: Primeiro Agente

### **2.1 Criar arquivo `primeiro_agente.py`**

```python
from mangaba_ai import MangabaAI
import asyncio

async def main():
    # Inicializar framework
    print("ğŸš€ Inicializando Mangaba AI...")
    ai = MangabaAI()
    
    # Criar primeiro agente
    print("ğŸ¤– Criando primeiro agente...")
    assistente = ai.create_agent(
        name="assistente",
        role="Assistente Pessoal",
        goal="Ajudar usuÃ¡rios com tarefas gerais e responder perguntas"
    )
    
    # Testar o agente
    print("ğŸ’¬ Testando conversa...")
    resposta = await assistente.chat("OlÃ¡! Quem Ã© vocÃª e como pode me ajudar?")
    print(f"ğŸ¤– Assistente: {resposta}")
    
    # Segunda pergunta para testar contexto
    resposta2 = await assistente.chat("Qual foi minha primeira pergunta?")
    print(f"ğŸ¤– Assistente: {resposta2}")
    
    print("âœ… Primeiro agente funcionando!")

if __name__ == "__main__":
    asyncio.run(main())
```

### **2.2 Executar o exemplo**

```bash
python primeiro_agente.py
```

**SaÃ­da esperada:**
```
ğŸš€ Inicializando Mangaba AI...
ğŸ¤– Criando primeiro agente...
ğŸ’¬ Testando conversa...
ğŸ¤– Assistente: OlÃ¡! Eu sou seu assistente pessoal criado com Mangaba AI...
ğŸ¤– Assistente: Sua primeira pergunta foi sobre quem eu sou e como posso ajudar...
âœ… Primeiro agente funcionando!
```

---

## ğŸ”— Passo 3: ComunicaÃ§Ã£o Entre Agentes (A2A)

### **3.1 Criar `comunicacao_agentes.py`**

```python
from mangaba_ai import MangabaAI
import asyncio

async def exemplo_comunicacao():
    print("ğŸš€ Inicializando sistema multi-agente...")
    ai = MangabaAI()
    
    # Criar agentes especializados
    pesquisador = ai.create_agent(
        name="pesquisador",
        role="Pesquisador",
        goal="Coletar e organizar informaÃ§Ãµes"
    )
    
    analista = ai.create_agent(
        name="analista",
        role="Analista de Dados", 
        goal="Analisar informaÃ§Ãµes e gerar insights"
    )
    
    # SimulaÃ§Ã£o: Pesquisador coleta dados
    print("ğŸ” Pesquisador coletando dados...")
    dados_pesquisa = "Dados sobre tendÃªncias de IA em 2024: crescimento de 150% em adoÃ§Ã£o empresarial"
    
    # A2A: Pesquisador envia dados para Analista
    print("ğŸ“¤ Enviando dados via protocolo A2A...")
    await pesquisador.send_message(
        receiver="analista",
        content=dados_pesquisa,
        message_type="research_data",
        priority=2
    )
    
    # Analista recebe e processa dados
    print("ğŸ“¥ Analista processando dados recebidos...")
    mensagens = await analista.receive_messages()
    
    if mensagens:
        dados_recebidos = mensagens[0].content
        print(f"ğŸ“Š Dados recebidos: {dados_recebidos}")
        
        # Analista gera insights
        analise = await analista.chat(f"Analise os seguintes dados e gere insights: {dados_recebidos}")
        print(f"ğŸ§  AnÃ¡lise: {analise}")
        
        # Responder ao pesquisador
        await analista.send_message(
            receiver="pesquisador",
            content=f"AnÃ¡lise concluÃ­da: {analise}",
            message_type="analysis_result"
        )
    
    print("âœ… ComunicaÃ§Ã£o A2A funcionando!")

if __name__ == "__main__":
    asyncio.run(exemplo_comunicacao())
```

### **3.2 Executar exemplo A2A**

```bash
python comunicacao_agentes.py
```

---

## ğŸ§  Passo 4: Contexto Inteligente (MCP)

### **4.1 Criar `contexto_inteligente.py`**

```python
from mangaba_ai import MangabaAI
import asyncio

async def exemplo_contexto():
    print("ğŸ§  Demonstrando protocolo MCP...")
    ai = MangabaAI()
    
    # Criar agente com contexto
    especialista = ai.create_agent(
        name="especialista",
        role="Especialista em IA",
        goal="Fornecer consultoria especializada mantendo contexto"
    )
    
    # SessÃ£o 1: Estabelecer contexto
    print("\nğŸ“ SessÃ£o 1 - Estabelecendo contexto...")
    
    await especialista.chat("Trabalho na empresa TechCorp como CTO")
    await especialista.chat("Estamos implementando IA generativa em nossos produtos")
    await especialista.chat("Temos um orÃ§amento de R$ 500.000 para este projeto")
    
    # Teste de contexto
    resposta = await especialista.chat("Considerando meu perfil e orÃ§amento, que soluÃ§Ãµes vocÃª recomenda?")
    print(f"ğŸ¤– Especialista: {resposta}")
    
    # SessÃ£o 2: Usar contexto em nova conversa
    print("\nğŸ”„ SessÃ£o 2 - Usando contexto anterior...")
    
    resposta2 = await especialista.chat("Qual Ã© minha funÃ§Ã£o na empresa mesmo?")
    print(f"ğŸ¤– Especialista: {resposta2}")
    
    # Demonstrar busca semÃ¢ntica no contexto
    print("\nğŸ” Busca semÃ¢ntica no contexto...")
    resultados = await especialista.mcp_protocol.semantic_search(
        query="orÃ§amento financeiro",
        limit=3
    )
    
    print("ğŸ“Š InformaÃ§Ãµes relacionadas a orÃ§amento:")
    for resultado in resultados:
        print(f"  - {resultado.content} (relevÃ¢ncia: {resultado.relevance:.2f})")
    
    print("âœ… Protocolo MCP funcionando!")

if __name__ == "__main__":
    asyncio.run(exemplo_contexto())
```

### **4.2 Executar exemplo MCP**

```bash
python contexto_inteligente.py
```

---

## ğŸ¢ Passo 5: Sistema Multi-Agente Completo

### **5.1 Criar `sistema_completo.py`**

```python
from mangaba_ai import MangabaAI
import asyncio

class SistemaAtendimento:
    def __init__(self):
        self.ai = MangabaAI()
        self._criar_agentes()
    
    def _criar_agentes(self):
        """Cria equipe de agentes especializados."""
        # Recepcionista: primeira linha de atendimento
        self.recepcionista = self.ai.create_agent(
            name="recepcionista",
            role="Atendente de Primeira Linha",
            goal="Receber e classificar solicitaÃ§Ãµes de clientes"
        )
        
        # TÃ©cnico: problemas tÃ©cnicos
        self.tecnico = self.ai.create_agent(
            name="tecnico",
            role="Suporte TÃ©cnico",
            goal="Resolver problemas tÃ©cnicos complexos"
        )
        
        # Vendedor: questÃµes comerciais
        self.vendedor = self.ai.create_agent(
            name="vendedor",
            role="Consultor de Vendas",
            goal="Auxiliar com questÃµes comerciais e vendas"
        )
        
        # Supervisor: escalaÃ§Ã£o e qualidade
        self.supervisor = self.ai.create_agent(
            name="supervisor",
            role="Supervisor de Atendimento",
            goal="Garantir qualidade e resolver casos complexos"
        )
    
    async def processar_solicitacao(self, mensagem_cliente, cliente_id="cliente_123"):
        """Processa solicitaÃ§Ã£o completa do cliente."""
        
        print(f"ğŸ“ Nova solicitaÃ§Ã£o do cliente {cliente_id}")
        print(f"ğŸ“ Mensagem: {mensagem_cliente}")
        
        # 1. Recepcionista classifica a solicitaÃ§Ã£o
        print("\nğŸ¯ Classificando solicitaÃ§Ã£o...")
        
        classificacao = await self.recepcionista.chat(
            f"Classifique esta solicitaÃ§Ã£o em 'tecnico', 'vendas' ou 'supervisor': {mensagem_cliente}"
        )
        
        # Extrair categoria (simplificado)
        if "tecnico" in classificacao.lower():
            categoria = "tecnico"
        elif "vendas" in classificacao.lower():
            categoria = "vendas"
        else:
            categoria = "supervisor"
        
        print(f"ğŸ“‹ Categoria identificada: {categoria}")
        
        # 2. MCP: Estabelecer contexto do cliente
        agente_especializado = getattr(self, categoria)
        
        with agente_especializado.mcp_protocol.session(cliente_id) as sessao:
            # 3. A2A: Recepcionista envia dados para especialista
            print(f"\nğŸ“¤ Encaminhando para {categoria}...")
            
            await self.recepcionista.send_message(
                receiver=categoria,
                content={
                    "cliente_id": cliente_id,
                    "solicitacao": mensagem_cliente,
                    "classificacao": classificacao
                },
                message_type="customer_request",
                priority=2
            )
            
            # 4. Especialista processa
            mensagens = await agente_especializado.receive_messages()
            if mensagens:
                dados = mensagens[0].content
                
                resposta = await agente_especializado.chat(
                    f"Atenda esta solicitaÃ§Ã£o: {dados['solicitacao']}"
                )
                
                print(f"ğŸ¤– {categoria.title()}: {resposta}")
                
                # 5. Se necessÃ¡rio, escalar para supervisor
                if "complexo" in resposta.lower() or "supervisor" in resposta.lower():
                    print("\nâ¬†ï¸ Escalando para supervisor...")
                    
                    await agente_especializado.send_message(
                        receiver="supervisor",
                        content={
                            "cliente_id": cliente_id,
                            "solicitacao_original": mensagem_cliente,
                            "tentativa_resolucao": resposta,
                            "agente_anterior": categoria
                        },
                        message_type="escalation",
                        priority=3
                    )
                    
                    # Supervisor trata escalaÃ§Ã£o
                    mensagens_supervisor = await self.supervisor.receive_messages()
                    if mensagens_supervisor:
                        escalacao = mensagens_supervisor[0].content
                        resposta_final = await self.supervisor.chat(
                            f"Resolva esta escalaÃ§Ã£o: {escalacao}"
                        )
                        print(f"ğŸ‘” Supervisor: {resposta_final}")
                        return resposta_final
                
                return resposta
        
        return "Erro no processamento"

async def main():
    print("ğŸ¢ Inicializando Sistema de Atendimento Multi-Agente...")
    
    sistema = SistemaAtendimento()
    
    # Simular diferentes tipos de solicitaÃ§Ãµes
    solicitacoes = [
        "Meu software estÃ¡ apresentando erro 500 constantemente",
        "Gostaria de saber sobre os planos Enterprise disponÃ­veis",
        "Preciso cancelar minha assinatura imediatamente"
    ]
    
    for i, solicitacao in enumerate(solicitacoes, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ“‹ SOLICITAÃ‡ÃƒO {i}")
        print(f"{'='*60}")
        
        resposta = await sistema.processar_solicitacao(
            solicitacao, 
            f"cliente_{i:03d}"
        )
        
        print(f"\nâœ… SolicitaÃ§Ã£o {i} processada!")
        await asyncio.sleep(1)  # Pausa entre solicitaÃ§Ãµes
    
    print(f"\n{'='*60}")
    print("ğŸ‰ Sistema Multi-Agente funcionando perfeitamente!")
    print("âœ… Protocolos A2A e MCP integrados com sucesso!")

if __name__ == "__main__":
    asyncio.run(main())
```

### **5.2 Executar sistema completo**

```bash
python sistema_completo.py
```

---

## ğŸ¯ PrÃ³ximos Passos

ParabÃ©ns! ğŸ‰ VocÃª concluiu o tutorial bÃ¡sico. Agora vocÃª pode:

### **ğŸ“š Aprofundar Conhecimentos**
- **[ğŸŒ Exemplos AvanÃ§ados de Protocolos](exemplos-protocolos.md)** - A2A e MCP detalhados
- **[â­ Melhores PrÃ¡ticas](melhores-praticas.md)** - OtimizaÃ§Ã£o e padrÃµes
- **[ğŸ—ï¸ Arquitetura AvanÃ§ada](arquitetura-avancada.md)** - Detalhes tÃ©cnicos

### **ğŸ› ï¸ Expandir Funcionalidades**
- Adicionar novas ferramentas aos agentes
- Integrar com APIs externas (Slack, Discord, etc.)
- Implementar persistent storage
- Criar interfaces web

### **ğŸ¤ Contribuir**
- **[ğŸ“‹ Como Contribuir](contribuicao.md)** - Junte-se Ã  comunidade
- Reporte bugs ou solicite features
- Melhore a documentaÃ§Ã£o
- Compartilhe seus casos de uso

### **ğŸ†˜ Obter Ajuda**
- **[â“ FAQ](faq.md)** - Perguntas frequentes
- **[GitHub Issues](https://github.com/Mangaba-ai/mangaba_ai/issues)** - Problemas tÃ©cnicos
- **[Discussions](https://github.com/Mangaba-ai/mangaba_ai/discussions)** - Comunidade

---

## ğŸ“ Resumo do que Aprendeu

âœ… **ConfiguraÃ§Ã£o**: Ambiente e API keys  
âœ… **Agentes**: CriaÃ§Ã£o e configuraÃ§Ã£o bÃ¡sica  
âœ… **A2A**: ComunicaÃ§Ã£o entre agentes  
âœ… **MCP**: Contexto e memÃ³ria inteligente  
âœ… **Sistema Multi-Agente**: IntegraÃ§Ã£o completa  

---

> ğŸš€ **PrÃ³ximo Passo Recomendado**: Explore os [Exemplos de Protocolos](exemplos-protocolos.md) para casos de uso mais avanÃ§ados!